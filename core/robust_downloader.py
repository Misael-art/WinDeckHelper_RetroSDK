"""Downloader robusto com retry, checksum e rollback
Implementa download seguro com verifica√ß√£o de integridade e limpeza autom√°tica"""

import os
import hashlib
import shutil
import time
import urllib.request
import urllib.error
from pathlib import Path
from typing import Optional, Dict, Callable
import logging
import py7zr
import zipfile
import tarfile

from config.retro_devkit_constants import (
    DOWNLOAD_MAX_RETRIES, DOWNLOAD_TIMEOUT, TEMP_DOWNLOAD_PATH
)

class RobustDownloader:
    """Downloader com retry, verifica√ß√£o de checksum e rollback autom√°tico"""
    
    def __init__(self, logger: logging.Logger, base_path: Path):
        self.logger = logger
        self.base_path = base_path
        self.temp_path = base_path / TEMP_DOWNLOAD_PATH
        self.temp_path.mkdir(exist_ok=True)
        
    def download_and_extract(
        self,
        url: str,
        extract_path: Path,
        expected_checksum: Optional[str] = None,
        progress_callback: Optional[Callable[[int, int], None]] = None
    ) -> bool:
        """Download e extra√ß√£o com verifica√ß√£o completa"""
        
        # Determinar nome do arquivo
        filename = url.split('/')[-1]
        download_path = self.temp_path / filename
        
        try:
            # Fase 1: Download com retry
            if not self._download_with_retry(url, download_path, progress_callback):
                return False
                
            # Fase 2: Verifica√ß√£o de checksum
            if expected_checksum and not self._verify_checksum(download_path, expected_checksum):
                self._cleanup_files([download_path])
                return False
                
            # Fase 3: Backup da pasta de destino (se existir)
            backup_path = None
            if extract_path.exists():
                backup_path = self._create_backup(extract_path)
                
            # Fase 4: Extra√ß√£o
            if not self._extract_archive(download_path, extract_path):
                # Rollback em caso de falha
                if backup_path:
                    self._restore_backup(backup_path, extract_path)
                self._cleanup_files([download_path])
                return False
                
            # Fase 5: Verifica√ß√£o p√≥s-extra√ß√£o
            if not self._verify_extraction(extract_path):
                # Rollback em caso de falha
                if backup_path:
                    self._restore_backup(backup_path, extract_path)
                else:
                    self._cleanup_directories([extract_path])
                self._cleanup_files([download_path])
                return False
                
            # Fase 6: Limpeza final
            self._cleanup_files([download_path])
            if backup_path:
                self._cleanup_directories([backup_path])
                
            self.logger.info(f"‚úÖ Download e extra√ß√£o conclu√≠dos: {extract_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro durante download/extra√ß√£o: {e}")
            self._cleanup_files([download_path])
            return False
            
    def _download_with_retry(
        self,
        url: str,
        file_path: Path,
        progress_callback: Optional[Callable[[int, int], None]] = None
    ) -> bool:
        """Download com retry autom√°tico"""
        
        for attempt in range(1, DOWNLOAD_MAX_RETRIES + 1):
            try:
                self.logger.info(f"üì• Tentativa {attempt}/{DOWNLOAD_MAX_RETRIES}: {url}")
                
                # Remover arquivo parcial se existir
                if file_path.exists():
                    file_path.unlink()
                    
                # Download com progress callback
                def reporthook(block_num, block_size, total_size):
                    if progress_callback:
                        progress_callback(block_num * block_size, total_size)
                        
                urllib.request.urlretrieve(url, file_path, reporthook)
                
                # Verificar se arquivo foi baixado completamente
                if file_path.exists() and file_path.stat().st_size > 0:
                    self.logger.info(f"‚úÖ Download conclu√≠do: {file_path.name}")
                    return True
                    
            except urllib.error.URLError as e:
                self.logger.warning(f"‚ö†Ô∏è Erro de rede (tentativa {attempt}): {e}")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Erro no download (tentativa {attempt}): {e}")
                
            if attempt < DOWNLOAD_MAX_RETRIES:
                wait_time = 2 ** attempt  # Backoff exponencial
                self.logger.info(f"‚è≥ Aguardando {wait_time}s antes da pr√≥xima tentativa...")
                time.sleep(wait_time)
                
        self.logger.error(f"‚ùå Falha no download ap√≥s {DOWNLOAD_MAX_RETRIES} tentativas")
        return False
        
    def _verify_checksum(self, file_path: Path, expected_checksum: str) -> bool:
        """Verifica checksum SHA-256 do arquivo"""
        try:
            self.logger.info("üîç Verificando integridade do arquivo...")
            
            sha256_hash = hashlib.sha256()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    sha256_hash.update(chunk)
                    
            actual_checksum = sha256_hash.hexdigest()
            
            if actual_checksum.lower() == expected_checksum.lower():
                self.logger.info("‚úÖ Checksum verificado com sucesso")
                return True
            else:
                self.logger.error(
                    f"‚ùå Checksum inv√°lido!\n"
                    f"Esperado: {expected_checksum}\n"
                    f"Atual: {actual_checksum}"
                )
                return False
                
        except Exception as e:
            self.logger.error(f"‚ùå Erro na verifica√ß√£o de checksum: {e}")
            return False
            
    def _extract_archive(self, archive_path: Path, extract_path: Path) -> bool:
        """Extrai arquivo usando biblioteca Python apropriada"""
        try:
            self.logger.info(f"üì¶ Extraindo {archive_path.name}...")
            
            # Criar diret√≥rio de destino
            extract_path.mkdir(parents=True, exist_ok=True)
            
            # Determinar tipo de arquivo e extrair
            if archive_path.suffix.lower() == '.7z':
                with py7zr.SevenZipFile(archive_path, 'r') as archive:
                    archive.extractall(path=extract_path)
            elif archive_path.suffix.lower() == '.zip':
                with zipfile.ZipFile(archive_path, 'r') as archive:
                    archive.extractall(path=extract_path)
            elif archive_path.suffix.lower() in ['.tar', '.tar.gz', '.tgz']:
                with tarfile.open(archive_path, 'r:*') as archive:
                    archive.extractall(path=extract_path)
            else:
                self.logger.error(f"‚ùå Formato de arquivo n√£o suportado: {archive_path.suffix}")
                return False
                
            self.logger.info("‚úÖ Extra√ß√£o conclu√≠da")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro na extra√ß√£o: {e}")
            return False
            
    def _verify_extraction(self, extract_path: Path) -> bool:
        """Verifica se a extra√ß√£o foi bem-sucedida"""
        try:
            if not extract_path.exists():
                self.logger.error("‚ùå Diret√≥rio de extra√ß√£o n√£o existe")
                return False
                
            # Listar conte√∫do para diagn√≥stico
            contents = list(extract_path.iterdir())
            if not contents:
                self.logger.error("‚ùå Diret√≥rio de extra√ß√£o est√° vazio")
                self._log_directory_contents(extract_path)
                return False
                
            self.logger.info(f"‚úÖ Extra√ß√£o verificada: {len(contents)} itens extra√≠dos")
            self._log_directory_contents(extract_path)
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro na verifica√ß√£o de extra√ß√£o: {e}")
            return False
            
    def _create_backup(self, path: Path) -> Optional[Path]:
        """Cria backup de um diret√≥rio"""
        try:
            timestamp = int(time.time())
            backup_path = self.base_path / "backups" / f"{path.name}_backup_{timestamp}"
            backup_path.parent.mkdir(parents=True, exist_ok=True)
            
            self.logger.info(f"üíæ Criando backup: {backup_path}")
            shutil.copytree(path, backup_path)
            return backup_path
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Falha ao criar backup: {e}")
            return None
            
    def _restore_backup(self, backup_path: Path, target_path: Path) -> bool:
        """Restaura backup"""
        try:
            self.logger.info(f"üîÑ Restaurando backup: {backup_path} -> {target_path}")
            
            if target_path.exists():
                shutil.rmtree(target_path)
                
            shutil.copytree(backup_path, target_path)
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå Falha ao restaurar backup: {e}")
            return False
            
    def _cleanup_files(self, file_paths: list[Path]) -> None:
        """Remove arquivos tempor√°rios"""
        for file_path in file_paths:
            try:
                if file_path.exists():
                    file_path.unlink()
                    self.logger.debug(f"üóëÔ∏è Arquivo removido: {file_path}")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Falha ao remover arquivo {file_path}: {e}")
                
    def _cleanup_directories(self, dir_paths: list[Path]) -> None:
        """Remove diret√≥rios tempor√°rios"""
        for dir_path in dir_paths:
            try:
                if dir_path.exists():
                    shutil.rmtree(dir_path)
                    self.logger.debug(f"üóëÔ∏è Diret√≥rio removido: {dir_path}")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Falha ao remover diret√≥rio {dir_path}: {e}")
                
    def _log_directory_contents(self, path: Path, max_items: int = 20) -> None:
        """Registra conte√∫do do diret√≥rio para diagn√≥stico"""
        try:
            if not path.exists():
                self.logger.debug(f"üìÅ Diret√≥rio n√£o existe: {path}")
                return
                
            contents = list(path.iterdir())
            self.logger.debug(f"üìÅ Conte√∫do de {path} ({len(contents)} itens):")
            
            for i, item in enumerate(contents[:max_items]):
                item_type = "üìÅ" if item.is_dir() else "üìÑ"
                size = f" ({item.stat().st_size} bytes)" if item.is_file() else ""
                self.logger.debug(f"  {item_type} {item.name}{size}")
                
            if len(contents) > max_items:
                self.logger.debug(f"  ... e mais {len(contents) - max_items} itens")
                
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erro ao listar diret√≥rio {path}: {e}")