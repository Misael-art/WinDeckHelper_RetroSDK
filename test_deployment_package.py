#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Teste do Pacote de Deployment
Testa se o pacote de deployment foi criado corretamente e funciona.
"""

import os
import sys
import subprocess
import logging
from pathlib import Path
import json
import time

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DeploymentTester:
    """Testador do pacote de deployment"""
    
    def __init__(self):
        self.project_root = Path.cwd()
        self.deployment_dir = self.project_root / "deployment"
        self.package_dir = None
        self.test_results = {
            "timestamp": time.time(),
            "tests": {},
            "overall_status": "unknown"
        }
    
    def find_package_directory(self):
        """Encontra o diret√≥rio do pacote"""
        logger.info("üîç Procurando pacote de deployment...")
        
        possible_dirs = [
            self.deployment_dir / "EnvironmentDevDeepEvaluation_Portable",
            self.deployment_dir / "package",
            self.project_root / "dist" / "EnvironmentDevDeepEvaluation"
        ]
        
        for dir_path in possible_dirs:
            if dir_path.exists():
                self.package_dir = dir_path
                logger.info(f"  ‚úÖ Pacote encontrado: {dir_path}")
                return True
        
        logger.error("  ‚ùå Pacote n√£o encontrado")
        return False
    
    def test_package_structure(self):
        """Testa a estrutura do pacote"""
        logger.info("üìÅ Testando estrutura do pacote...")
        
        required_items = [
            "EnvironmentDevDeepEvaluation",  # Diret√≥rio do execut√°vel
            "config",                        # Configura√ß√µes
            "docs",                         # Documenta√ß√£o
            "LEIA-ME.txt",                  # Arquivo de informa√ß√µes
        ]
        
        optional_items = [
            "data",                         # Dados iniciais
            "Iniciar_Environment_Dev.bat", # Script Windows
            "iniciar_environment_dev.sh",  # Script Linux/Mac
        ]
        
        missing_required = []
        missing_optional = []
        
        for item in required_items:
            item_path = self.package_dir / item
            if not item_path.exists():
                missing_required.append(item)
            else:
                logger.info(f"  ‚úÖ Encontrado: {item}")
        
        for item in optional_items:
            item_path = self.package_dir / item
            if not item_path.exists():
                missing_optional.append(item)
            else:
                logger.info(f"  ‚úÖ Encontrado: {item}")
        
        test_passed = len(missing_required) == 0
        self.test_results["tests"]["package_structure"] = {
            "status": "pass" if test_passed else "fail",
            "missing_required": missing_required,
            "missing_optional": missing_optional
        }
        
        if test_passed:
            logger.info("  ‚úÖ Estrutura do pacote OK")
        else:
            logger.error(f"  ‚ùå Itens obrigat√≥rios ausentes: {missing_required}")
        
        return test_passed
    
    def test_executable_exists(self):
        """Testa se o execut√°vel existe"""
        logger.info("üîß Testando exist√™ncia do execut√°vel...")
        
        exe_dir = self.package_dir / "EnvironmentDevDeepEvaluation"
        exe_file = exe_dir / "EnvironmentDevDeepEvaluation.exe"
        exe_file_linux = exe_dir / "EnvironmentDevDeepEvaluation"
        
        exe_exists = exe_file.exists() or exe_file_linux.exists()
        
        if exe_exists:
            exe_path = exe_file if exe_file.exists() else exe_file_linux
            exe_size = exe_path.stat().st_size / (1024 * 1024)  # MB
            logger.info(f"  ‚úÖ Execut√°vel encontrado: {exe_path.name}")
            logger.info(f"  üìä Tamanho: {exe_size:.1f} MB")
        else:
            logger.error("  ‚ùå Execut√°vel n√£o encontrado")
        
        self.test_results["tests"]["executable_exists"] = {
            "status": "pass" if exe_exists else "fail",
            "executable_path": str(exe_path) if exe_exists else None,
            "size_mb": f"{exe_size:.1f}" if exe_exists else None
        }
        
        return exe_exists
    
    def test_configuration_files(self):
        """Testa se os arquivos de configura√ß√£o existem"""
        logger.info("‚öôÔ∏è Testando arquivos de configura√ß√£o...")
        
        config_dir = self.package_dir / "config"
        required_configs = [
            "components",  # Diret√≥rio de componentes
        ]
        
        missing_configs = []
        for config in required_configs:
            config_path = config_dir / config
            if not config_path.exists():
                missing_configs.append(config)
            else:
                if config_path.is_dir():
                    file_count = len(list(config_path.glob("*.yaml")))
                    logger.info(f"  ‚úÖ {config}: {file_count} arquivos YAML")
                else:
                    logger.info(f"  ‚úÖ {config}: arquivo encontrado")
        
        test_passed = len(missing_configs) == 0
        self.test_results["tests"]["configuration_files"] = {
            "status": "pass" if test_passed else "fail",
            "missing_configs": missing_configs
        }
        
        if test_passed:
            logger.info("  ‚úÖ Arquivos de configura√ß√£o OK")
        else:
            logger.error(f"  ‚ùå Configura√ß√µes ausentes: {missing_configs}")
        
        return test_passed
    
    def test_documentation(self):
        """Testa se a documenta√ß√£o existe"""
        logger.info("üìö Testando documenta√ß√£o...")
        
        docs_dir = self.package_dir / "docs"
        readme_file = self.package_dir / "LEIA-ME.txt"
        
        docs_exist = docs_dir.exists()
        readme_exists = readme_file.exists()
        
        if docs_exist:
            doc_count = len(list(docs_dir.glob("*.md")))
            logger.info(f"  ‚úÖ Documenta√ß√£o: {doc_count} arquivos")
        else:
            logger.warning("  ‚ö† Diret√≥rio de documenta√ß√£o n√£o encontrado")
        
        if readme_exists:
            readme_size = readme_file.stat().st_size
            logger.info(f"  ‚úÖ LEIA-ME.txt: {readme_size} bytes")
        else:
            logger.warning("  ‚ö† LEIA-ME.txt n√£o encontrado")
        
        test_passed = docs_exist or readme_exists
        self.test_results["tests"]["documentation"] = {
            "status": "pass" if test_passed else "fail",
            "docs_dir_exists": docs_exist,
            "readme_exists": readme_exists
        }
        
        return test_passed
    
    def test_startup_scripts(self):
        """Testa os scripts de inicializa√ß√£o"""
        logger.info("üöÄ Testando scripts de inicializa√ß√£o...")
        
        bat_script = self.package_dir / "Iniciar_Environment_Dev.bat"
        sh_script = self.package_dir / "iniciar_environment_dev.sh"
        
        bat_exists = bat_script.exists()
        sh_exists = sh_script.exists()
        
        if bat_exists:
            logger.info("  ‚úÖ Script Windows (.bat) encontrado")
        else:
            logger.warning("  ‚ö† Script Windows n√£o encontrado")
        
        if sh_exists:
            logger.info("  ‚úÖ Script Linux/Mac (.sh) encontrado")
            # Verificar se √© execut√°vel
            try:
                is_executable = os.access(sh_script, os.X_OK)
                if is_executable:
                    logger.info("  ‚úÖ Script Linux/Mac √© execut√°vel")
                else:
                    logger.warning("  ‚ö† Script Linux/Mac n√£o √© execut√°vel")
            except:
                pass
        else:
            logger.warning("  ‚ö† Script Linux/Mac n√£o encontrado")
        
        test_passed = bat_exists or sh_exists
        self.test_results["tests"]["startup_scripts"] = {
            "status": "pass" if test_passed else "fail",
            "bat_exists": bat_exists,
            "sh_exists": sh_exists
        }
        
        return test_passed
    
    def test_executable_dependencies(self):
        """Testa se o execut√°vel tem todas as depend√™ncias"""
        logger.info("üîó Testando depend√™ncias do execut√°vel...")
        
        exe_dir = self.package_dir / "EnvironmentDevDeepEvaluation"
        
        # Verificar se existem bibliotecas essenciais
        essential_libs = [
            "_internal",  # Diret√≥rio interno do PyInstaller
        ]
        
        missing_libs = []
        for lib in essential_libs:
            lib_path = exe_dir / lib
            if not lib_path.exists():
                missing_libs.append(lib)
            else:
                if lib_path.is_dir():
                    file_count = len(list(lib_path.rglob("*")))
                    logger.info(f"  ‚úÖ {lib}: {file_count} arquivos")
                else:
                    logger.info(f"  ‚úÖ {lib}: encontrado")
        
        # Calcular tamanho total
        total_size = 0
        file_count = 0
        for file_path in exe_dir.rglob("*"):
            if file_path.is_file():
                total_size += file_path.stat().st_size
                file_count += 1
        
        size_mb = total_size / (1024 * 1024)
        logger.info(f"  üìä Total: {file_count} arquivos, {size_mb:.1f} MB")
        
        test_passed = len(missing_libs) == 0
        self.test_results["tests"]["executable_dependencies"] = {
            "status": "pass" if test_passed else "fail",
            "missing_libs": missing_libs,
            "total_files": file_count,
            "total_size_mb": f"{size_mb:.1f}"
        }
        
        return test_passed
    
    def run_quick_executable_test(self):
        """Executa um teste r√°pido do execut√°vel"""
        logger.info("‚ö° Executando teste r√°pido do execut√°vel...")
        
        exe_dir = self.package_dir / "EnvironmentDevDeepEvaluation"
        exe_file = exe_dir / "EnvironmentDevDeepEvaluation.exe"
        exe_file_linux = exe_dir / "EnvironmentDevDeepEvaluation"
        
        exe_path = exe_file if exe_file.exists() else exe_file_linux
        
        if not exe_path.exists():
            logger.error("  ‚ùå Execut√°vel n√£o encontrado para teste")
            return False
        
        try:
            # Tentar executar com --help ou --version (se suportado)
            # Como n√£o sabemos se o execut√°vel suporta esses par√¢metros,
            # vamos apenas verificar se ele pode ser executado
            logger.info("  ‚ÑπÔ∏è Teste de execu√ß√£o n√£o implementado (requer GUI)")
            logger.info("  ‚úÖ Execut√°vel existe e parece v√°lido")
            
            self.test_results["tests"]["executable_test"] = {
                "status": "skip",
                "reason": "GUI application - manual test required"
            }
            
            return True
            
        except Exception as e:
            logger.error(f"  ‚ùå Erro no teste do execut√°vel: {e}")
            self.test_results["tests"]["executable_test"] = {
                "status": "fail",
                "error": str(e)
            }
            return False
    
    def generate_test_report(self):
        """Gera relat√≥rio dos testes"""
        logger.info("üìä Gerando relat√≥rio de testes...")
        
        # Calcular estat√≠sticas
        total_tests = len(self.test_results["tests"])
        passed_tests = sum(1 for test in self.test_results["tests"].values() 
                          if test["status"] == "pass")
        failed_tests = sum(1 for test in self.test_results["tests"].values() 
                          if test["status"] == "fail")
        skipped_tests = sum(1 for test in self.test_results["tests"].values() 
                           if test["status"] == "skip")
        
        # Determinar status geral
        if failed_tests == 0:
            overall_status = "pass"
        elif passed_tests > failed_tests:
            overall_status = "partial"
        else:
            overall_status = "fail"
        
        self.test_results["overall_status"] = overall_status
        self.test_results["statistics"] = {
            "total": total_tests,
            "passed": passed_tests,
            "failed": failed_tests,
            "skipped": skipped_tests
        }
        
        # Salvar relat√≥rio
        report_file = self.deployment_dir / f"test_report_{int(time.time())}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"  ‚úÖ Relat√≥rio salvo: {report_file}")
        
        # Mostrar resumo
        print(f"\nüìä RESUMO DOS TESTES")
        print("=" * 30)
        print(f"Total de testes: {total_tests}")
        print(f"‚úÖ Passou: {passed_tests}")
        print(f"‚ùå Falhou: {failed_tests}")
        print(f"‚è≠Ô∏è Pulado: {skipped_tests}")
        print(f"Status geral: {overall_status.upper()}")
        
        return overall_status
    
    def run_all_tests(self):
        """Executa todos os testes"""
        logger.info("üß™ Iniciando testes do pacote de deployment...")
        
        if not self.find_package_directory():
            return False
        
        tests = [
            ("Estrutura do Pacote", self.test_package_structure),
            ("Execut√°vel", self.test_executable_exists),
            ("Configura√ß√µes", self.test_configuration_files),
            ("Documenta√ß√£o", self.test_documentation),
            ("Scripts de Inicializa√ß√£o", self.test_startup_scripts),
            ("Depend√™ncias", self.test_executable_dependencies),
            ("Teste R√°pido", self.run_quick_executable_test),
        ]
        
        for test_name, test_func in tests:
            logger.info(f"\n--- {test_name} ---")
            try:
                test_func()
            except Exception as e:
                logger.error(f"‚ùå Erro no teste '{test_name}': {e}")
                self.test_results["tests"][test_name.lower().replace(" ", "_")] = {
                    "status": "error",
                    "error": str(e)
                }
        
        # Gerar relat√≥rio final
        overall_status = self.generate_test_report()
        
        return overall_status in ["pass", "partial"]

def main():
    """Fun√ß√£o principal"""
    print("üß™ Environment Dev Deep Evaluation - Teste de Deployment")
    print("=" * 60)
    
    tester = DeploymentTester()
    success = tester.run_all_tests()
    
    if success:
        print("\n‚úÖ TESTES CONCLU√çDOS COM SUCESSO!")
        print("O pacote de deployment est√° pronto para distribui√ß√£o.")
    else:
        print("\n‚ùå ALGUNS TESTES FALHARAM!")
        print("Verifique os erros acima antes de distribuir o pacote.")
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)